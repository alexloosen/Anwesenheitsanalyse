{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e7047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drill-Funktionen importieren\n",
    "import drill as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b35614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as mplt\n",
    "import plotly.express as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cyclical(data, col, max_val):\n",
    "    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e65dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(data):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=data['timestamp'], \n",
    "                             y=data['co2_ppm'], \n",
    "                             mode='markers',\n",
    "                             marker=dict(\n",
    "                                 color=(\n",
    "                                    (data['presence'] == 0)).astype('int'),\n",
    "                                    colorscale=[[0, 'yellow'], [1, 'blue']])))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cdf8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = d.get_PIR_data()\n",
    "#df.to_json('data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data.json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df, x='timestamp', y='co2_ppm', color='presence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c37859d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test = df\n",
    "\n",
    "df_nov = df.loc[(df['timestamp'] < pd.to_datetime(1636722000, unit='s', origin='unix')) &\n",
    "                (df['timestamp'] > pd.to_datetime(1634562000, unit='s', origin='unix'))]\n",
    "\n",
    "df_nov.reset_index(drop=True, inplace=True)\n",
    "# alle zwischen 18.10. und 22.11. entfernen\n",
    "df_test = df.drop(df[(df['timestamp'] > pd.to_datetime(1634518800, unit='s', origin='unix')) & \n",
    "                    (df['timestamp'] < pd.to_datetime(1637586000, unit='s', origin='unix'))].index)\n",
    "\n",
    "\n",
    "# timestamp etwas leichter zu verarbeiten, wenn als Integer gespeichert\n",
    "df_test = df_test.assign(hoursMinutesSeconds=lambda d: (d['timestamp'].dt.hour.astype('int') * 10000 + \n",
    "                                                        d['timestamp'].dt.minute.astype('int') * 100 + \n",
    "                                                       d['timestamp'].dt.second.astype('int')))\n",
    "\n",
    "df_test['hour_sin'] = np.sin(2 * np.pi * df_test['hoursMinutesSeconds']/235959.0)\n",
    "df_test['hour_cos'] = np.cos(2 * np.pi * df_test['hoursMinutesSeconds']/235959.0)\n",
    "\n",
    "df_nov = df_nov.assign(hoursMinutesSeconds=lambda d: (d['timestamp'].dt.hour.astype('int') * 10000 + \n",
    "                                                        d['timestamp'].dt.minute.astype('int') * 100 + \n",
    "                                                       d['timestamp'].dt.second.astype('int')))\n",
    "\n",
    "df_nov['hour_sin'] = np.sin(2 * np.pi * df_nov['hoursMinutesSeconds']/235959.0)\n",
    "df_nov['hour_cos'] = np.cos(2 * np.pi * df_nov['hoursMinutesSeconds']/235959.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775454c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_test, x='timestamp', y='co2_ppm', color='presence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80200ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erhoeht sich die Genauigkeit, wenn Datenset ausgeglichener ist?\n",
    "# Idee bei ca. 8 Stunden Anwesenheit:\n",
    "# Entferne 8 Nachtstunden von 22:00-05:00, \n",
    "# sodass von 24 stunden 8 Anwesenheits-Stunden und 8 Abwesenheits-Stunden uebrig bleiben\n",
    "df_test.drop(df_test[(df_test['hoursMinutesSeconds'] < 50000) |\n",
    "                     (df_test['hoursMinutesSeconds'] > 220000)].index, inplace=True)\n",
    "\n",
    "df_nov.drop(df_nov[(df_nov['hoursMinutesSeconds'] < 50000) |\n",
    "                     (df_nov['hoursMinutesSeconds'] > 220000)].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_nov, x='timestamp', y='co2_ppm', color='presence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template für mehrere Plots in einem Graphen\n",
    "#fig = create_plot(df_test)\n",
    "#df_test['co2_ppmShifted'] = df_test['co2_ppm'].shift(12)\n",
    "#fig.add_trace(go.Scatter(x=df_test['timestamp'], \n",
    "#                             y=df_test['co2_ppmShifted'], \n",
    "#                             mode='lines',\n",
    "#                             line=dict(width=2),\n",
    "#                             marker=dict(\n",
    "#                                 color=(\n",
    "#                                    (df_test['presence'] == 0)).astype('int'),\n",
    "#                                    colorscale=[[0, 'green'], [1, 'red']])))\n",
    "\n",
    "#fig.show()\n",
    "#plt.scatter(df_test, x='timestamp', y='co2_ppm', color='presence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steigungen mit Abstaenden 5, 30 und 60 Minuten einfuegen\n",
    "df_test['co2_ppm_deltaOne'] = df_test['co2_ppm'] - df_test.shift(1)['co2_ppm']\n",
    "df_test['co2_ppm_deltaSix'] = df_test['co2_ppm'] - df_test.shift(6)['co2_ppm']\n",
    "df_test['co2_ppm_deltaTwelve'] = df_test['co2_ppm'] - df_test.shift(12)['co2_ppm']\n",
    "#df_test['co2_ppm_deltaMinusOne'] = df_test.shift(-1)['co2_ppm'] - df_test['co2_ppm']\n",
    "#df_test['co2_ppm_deltaMinusSix'] = df_test.shift(-6)['co2_ppm'] - df_test['co2_ppm']\n",
    "#df_test['co2_ppm_deltaMinusTwelve'] = df_test.shift(-12)['co2_ppm'] - df_test['co2_ppm']\n",
    "\n",
    "# Falsche November-Daten ebenfalls mit Delta versehen\n",
    "df_nov['co2_ppm_deltaOne'] = df_nov['co2_ppm'] - df_nov.shift(1)['co2_ppm']\n",
    "df_nov['co2_ppm_deltaSix'] = df_nov['co2_ppm'] - df_nov.shift(6)['co2_ppm']\n",
    "df_nov['co2_ppm_deltaTwelve'] = df_nov['co2_ppm'] - df_nov.shift(12)['co2_ppm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e1263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wochentag einfuegen\n",
    "# verringert Genauigkeit, weil wahrscheinlich zu \"verlaesslich\"\n",
    "\n",
    "#df_test['dayOfWeek'] = df['timestamp'].dt.dayofweek\n",
    "#df_test = df_test.drop(df_test[df_test.dayOfWeek > 4].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausreisser mit Interquartile Range (IQR) und Tukey's Method loeschen\n",
    "# Idee: Fenster wird an fast allen Tagen ab ca. 1200-1300 ppm geoeffnet\n",
    "# -> was veraendert sich, wenn die Werte darüber entfernt werden und das Datenset so \"geglaettet\" wird?\n",
    "# Erhoeht Genauigkeit um ca. 2%\n",
    "x = df_test['co2_ppm']\n",
    "q1 = np.percentile(x, 12)\n",
    "q3 = np.percentile(x, 88)\n",
    "iqr = q3 - q1\n",
    "floor = q1 - 1.5*iqr\n",
    "ceiling = q3 + 1.5*iqr\n",
    "outlier_indices = list(x.index[(x < floor) | (x > ceiling)])\n",
    "outlier_values = list(x[outlier_indices])\n",
    "print(outlier_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48907d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(index=outlier_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcee49f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# timestamp, presence, temperatur und humidity entfernen\n",
    "# temp/humid erhoehen Genauigkeit deutlich, da relativ unverlaesslich -> von zu vielen aeusseren Faktoren abhaengig\n",
    "df_test = df_test.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "df_timestamp = df_test['timestamp']\n",
    "y_presence = df_test['presence']\n",
    "X_presence = df_test.drop(['timestamp', 'hoursMinutesSeconds', 'presence', 'temperature_celsius', 'relative_humidity_percent'], axis=1)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_presence, y_presence, test_size=0.2, random_state=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec61997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift des trainings-sets um 5 minuten in die Vergangenheit\n",
    "# -> Test ob Model auch in die Zukunft Erwartungen treffen kann\n",
    "#ytrain = ytrain.shift(-6)\n",
    "#ytrain.dropna(axis=0, how='any', inplace=False)\n",
    "#ytrain = ytrain.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301e2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classification\n",
    "modelClass = RandomForestClassifier(n_estimators=250)\n",
    "modelClass.fit(Xtrain, ytrain)\n",
    "ypred = modelClass.predict(X_presence)\n",
    "accuracy_score(y_presence, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_class = df_test.copy()\n",
    "df_valid_class['timestamp'] = df_timestamp\n",
    "df_valid_class['prediction'] = ypred\n",
    "df_valid_class['co2_ppm'] = df_test['co2_ppm']\n",
    "\n",
    "plt.scatter(df_valid_class, x='timestamp', y='co2_ppm', color='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638804d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot feature-importance\n",
    "feature_imp = pd.Series(modelClass.feature_importances_,index=Xtrain.columns).sort_values(ascending=False)\n",
    "# Creating a bar plot\n",
    "ax = sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "ax.set(xlabel='Importance', ylabel='Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7704563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Cross-Validation with Random Forest Classifier\n",
    "ytest_model = modelClass.fit(Xtrain, ytrain).predict(Xtest)\n",
    "ytrain_model = modelClass.fit(Xtest, ytest).predict(Xtrain)\n",
    "accuracy_score(ytrain, ytrain_model), accuracy_score(ytest, ytest_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1888f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(modelClass, X_presence, y_presence, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d7680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "modelReg = RandomForestRegressor(n_estimators=250)\n",
    "modelReg.fit(Xtrain, ytrain)\n",
    "\n",
    "ypred = modelReg.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c584c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = Xtest.copy()\n",
    "df_valid['timestamp'] = df_timestamp\n",
    "df_valid['prediction'] = ypred\n",
    "df_valid['co2_ppm'] = df_test['co2_ppm']\n",
    "df_valid['presence'] = ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edbd649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)\n",
    "df_timestamp = df_test['timestamp']\n",
    "df_test.drop(['timestamp', 'hoursMinutesSeconds', 'presence', 'temperature_celsius', 'relative_humidity_percent'], axis=1, inplace=True)\n",
    "ypred = modelReg.predict(df_test)\n",
    "\n",
    "df_valid_test = df_test.copy()\n",
    "df_valid_test['timestamp'] = df_timestamp\n",
    "df_valid_test['prediction'] = ypred\n",
    "df_valid_test['co2_ppm'] = df_test['co2_ppm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af50ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_valid_test, x='timestamp', y='co2_ppm', color='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# falsche Werte im November korrigieren\n",
    "df_nov.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)\n",
    "df_timestamp_nov = df_nov['timestamp']\n",
    "df_nov.drop(['timestamp', 'hoursMinutesSeconds', 'presence', 'temperature_celsius', 'relative_humidity_percent'], axis=1, inplace=True)\n",
    "ypred_nov = modelReg.predict(df_nov)\n",
    "\n",
    "df_valid_nov = df_nov.copy()\n",
    "df_valid_nov['timestamp'] = df_timestamp_nov\n",
    "df_valid_nov['prediction'] = ypred_nov\n",
    "df_valid_nov['co2_ppm'] = df_nov['co2_ppm']\n",
    "\n",
    "df_valid_nov.loc[df_valid_nov['prediction'] >= 0.5, 'prediction'] = 1\n",
    "df_valid_nov.loc[df_valid_nov['prediction'] < 0.5, 'prediction'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64cbb1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_valid_nov, x='timestamp', y='co2_ppm', color='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4fdda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter tuning for Random Forest Models\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "#rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_reg = modelReg\n",
    "rf_random_reg = RandomizedSearchCV(estimator = rf_reg, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random_reg.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8f6202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "#rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_class = modelClass\n",
    "rf_random_class = RandomizedSearchCV(estimator = rf_class, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random_class.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07189642",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb6be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_class.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bcce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateClassifier(model, test_features, test_labels):\n",
    "    ypred = model.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels, ypred)\n",
    "    print('Model Performance')\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy*100))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcdf139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRegressor(model, test_features, test_labels):\n",
    "    ypred = modelReg.predict(test_features)\n",
    "    errors = abs(ypred - test_labels)\n",
    "    mse = mean_squared_error(test_labels, ypred)\n",
    "    rmse = sqrt(mse) * 100\n",
    "    accuracy = 100 - rmse\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.2f} degrees.'.format(np.mean(errors)*100))\n",
    "    print('Accuracy for Random Forest: {:0.2f}%.'.format(accuracy)) \n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5c49a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = modelClass\n",
    "base_model.fit(Xtrain, ytrain)\n",
    "base_accuracy = evaluateClassifier(base_model, Xtest, ytest)\n",
    "\n",
    "best_random = rf_random_class.best_estimator_\n",
    "random_accuracy = evaluateClassifier(best_random, Xtest, ytest)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b50437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = RandomForestRegressor(n_estimators = 250, random_state = 42)\n",
    "base_model = modelReg\n",
    "base_model.fit(Xtrain, ytrain)\n",
    "base_accuracy = evaluateRegressor(base_model, Xtest, ytest)\n",
    "\n",
    "best_random = rf_random_reg.best_estimator_\n",
    "random_accuracy = evaluateRegressor(best_random, Xtest, ytest)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc729c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
