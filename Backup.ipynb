{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e7047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drill-Funktionen importieren\n",
    "import drill as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b35614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as mplt\n",
    "import plotly.express as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cyclical(data, col, max_val):\n",
    "    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e65dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(data):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=data['timestamp'], \n",
    "                             y=data['co2_ppm'], \n",
    "                             mode='markers',\n",
    "                             marker=dict(\n",
    "                                 color=(\n",
    "                                    (data['presence'] == 0)).astype('int'),\n",
    "                                    colorscale=[[0, 'yellow'], [1, 'blue']])))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ba152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateClassifier(model, test_features, test_labels):\n",
    "    ypred = model.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels, ypred)\n",
    "    print('Model Performance')\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy*100))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05491eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.path.dirname(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a275482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameterTuning(modelType, estimator, Xtrain, ytrain, Xtest, ytest):\n",
    "    if (modelType == 'RF'):\n",
    "        base_class = RandomForestClassifier()\n",
    "        param_test = {\n",
    "            'n_estimators':[25, 50, 100, 250, 500, 1000],\n",
    "            'max_depth':[5,15,50],\n",
    "            'min_samples_split':[10,200,800],\n",
    "            'min_samples_leaf':[5,10,40],\n",
    "            'max_features':[1,2,3]\n",
    "            }\n",
    "    elif (modelType == 'GB'):\n",
    "        base_class = GradientBoostClassifier()\n",
    "        param_test = {\n",
    "            'n_estimators':[50, 100, 250],\n",
    "            'max_depth': [2,5,10],\n",
    "            'min_samples_split':[100, 500, 1200],\n",
    "            'min_samples_leaf':[10,30,50],\n",
    "            'max_features':[2,3],\n",
    "            'subsample':[0.6,0.75,0.9]\n",
    "             }    \n",
    "    elif (modelType == 'SVC'):\n",
    "        base_class = SVC()\n",
    "        param_test = {\n",
    "            'kernel':['poly','rbf', 'sigmoid','linear'],\n",
    "            'C': [1, 10, 100, 1000],\n",
    "            'gamma': [0.001, 0.0001]\n",
    "        }\n",
    "    gsearch1 = GridSearchCV(estimator = estimator,param_grid = param_test, scoring='roc_auc',verbose=5, n_jobs=-1, cv=3)\n",
    "    gsearch1.fit(Xtrain,ytrain)\n",
    "    \n",
    "    print('Optimized Parameters:')\n",
    "    print(gsearch1.best_params_)\n",
    "    base_accuracy = evaluateClassifier(baseClass, Xtest, ytest)\n",
    "    random_accuracy = evaluateClassifier(gsearch1, Xtest, ytest)\n",
    "    \n",
    "    print('Comparison Results:')\n",
    "    print('Base Accuracy: {:0.2f}%.'.format(100 * base_accuracy))\n",
    "    print('Optimized Accuracy: {:0.2f}%.'.format(100 * random_accuracy))\n",
    "    print('Improvement of {:0.2f}%.'.format(100 * (random_accuracy - base_accuracy) / base_accuracy))\n",
    "    return gsearch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9509e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectOutliers(df):\n",
    "    x = df['co2_ppm']\n",
    "    q1 = np.percentile(x, 12)\n",
    "    q3 = np.percentile(x, 88)\n",
    "    iqr = q3 - q1\n",
    "    floor = q1 - 1.5*iqr\n",
    "    ceiling = q3 + 1.5*iqr\n",
    "    outlier_indices = list(x.index[(x < floor) | (x > ceiling)])\n",
    "    outlier_values = list(x[outlier_indices])\n",
    "    print(outlier_values)\n",
    "    return outlier_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = d.get_PIR_data('H215')\n",
    "#df.to_json('H215.json')\n",
    "#df = d.get_PIR_data('H216')\n",
    "#df.to_json('H216.json')\n",
    "#df = d.get_PIR_data('H217')\n",
    "#df.to_json('H217.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cdf8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = d.get_PIR_data()\n",
    "#df.to_json('data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('H217.json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df, x='timestamp', y='co2_ppm', color='presence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c37859d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test = df\n",
    "\n",
    "df_nov = df.loc[(df['timestamp'] < pd.to_datetime(1636722000, unit='s', origin='unix')) &\n",
    "                (df['timestamp'] > pd.to_datetime(1634562000, unit='s', origin='unix'))]\n",
    "\n",
    "df_nov.reset_index(drop=True, inplace=True)\n",
    "# alle zwischen 18.10. und 22.11. entfernen\n",
    "df_test = df.drop(df[(df['timestamp'] > pd.to_datetime(1634518800, unit='s', origin='unix')) & \n",
    "                    (df['timestamp'] < pd.to_datetime(1637586000, unit='s', origin='unix'))].index)\n",
    "\n",
    "\n",
    "# timestamp etwas leichter zu verarbeiten, wenn als Integer gespeichert\n",
    "df_test = df_test.assign(hoursMinutesSeconds=lambda d: (d['timestamp'].dt.hour.astype('int') * 10000 + \n",
    "                                                        d['timestamp'].dt.minute.astype('int') * 100 + \n",
    "                                                       d['timestamp'].dt.second.astype('int')))\n",
    "\n",
    "df_test['hour_sin'] = np.sin(2 * np.pi * df_test['hoursMinutesSeconds']/235959.0)\n",
    "df_test['hour_cos'] = np.cos(2 * np.pi * df_test['hoursMinutesSeconds']/235959.0)\n",
    "\n",
    "df_nov = df_nov.assign(hoursMinutesSeconds=lambda d: (d['timestamp'].dt.hour.astype('int') * 10000 + \n",
    "                                                        d['timestamp'].dt.minute.astype('int') * 100 + \n",
    "                                                       d['timestamp'].dt.second.astype('int')))\n",
    "\n",
    "df_nov['hour_sin'] = np.sin(2 * np.pi * df_nov['hoursMinutesSeconds']/235959.0)\n",
    "df_nov['hour_cos'] = np.cos(2 * np.pi * df_nov['hoursMinutesSeconds']/235959.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775454c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_test, x='timestamp', y='co2_ppm', color='presence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80200ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erhoeht sich die Genauigkeit, wenn Datenset ausgeglichener ist?\n",
    "# Idee bei ca. 8 Stunden Anwesenheit:\n",
    "# Entferne 8 Nachtstunden von 22:00-05:00, \n",
    "# sodass von 24 stunden 8 Anwesenheits-Stunden und 8 Abwesenheits-Stunden uebrig bleiben\n",
    "df_test.drop(df_test[(df_test['hoursMinutesSeconds'] < 50000) |\n",
    "                     (df_test['hoursMinutesSeconds'] > 220000)].index, inplace=True)\n",
    "\n",
    "df_nov.drop(df_nov[(df_nov['hoursMinutesSeconds'] < 50000) |\n",
    "                     (df_nov['hoursMinutesSeconds'] > 220000)].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_nov, x='timestamp', y='co2_ppm', color='presence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template für mehrere Plots in einem Graphen\n",
    "#fig = create_plot(df_test)\n",
    "#df_test['co2_ppmShifted'] = df_test['co2_ppm'].shift(12)\n",
    "#fig.add_trace(go.Scatter(x=df_test['timestamp'], \n",
    "#                             y=df_test['co2_ppmShifted'], \n",
    "#                             mode='lines',\n",
    "#                             line=dict(width=2),\n",
    "#                             marker=dict(\n",
    "#                                 color=(\n",
    "#                                    (df_test['presence'] == 0)).astype('int'),\n",
    "#                                    colorscale=[[0, 'green'], [1, 'red']])))\n",
    "\n",
    "#fig.show()\n",
    "#plt.scatter(df_test, x='timestamp', y='co2_ppm', color='presence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steigungen mit Abstaenden 5, 30 und 60 Minuten einfuegen\n",
    "df_test['co2_ppm_deltaOne'] = df_test['co2_ppm'] - df_test.shift(1)['co2_ppm']\n",
    "df_test['co2_ppm_deltaSix'] = df_test['co2_ppm'] - df_test.shift(6)['co2_ppm']\n",
    "df_test['co2_ppm_deltaTwelve'] = df_test['co2_ppm'] - df_test.shift(12)['co2_ppm']\n",
    "#df_test['co2_ppm_deltaMinusOne'] = df_test.shift(-1)['co2_ppm'] - df_test['co2_ppm']\n",
    "#df_test['co2_ppm_deltaMinusSix'] = df_test.shift(-6)['co2_ppm'] - df_test['co2_ppm']\n",
    "#df_test['co2_ppm_deltaMinusTwelve'] = df_test.shift(-12)['co2_ppm'] - df_test['co2_ppm']\n",
    "\n",
    "# Falsche November-Daten ebenfalls mit Delta versehen\n",
    "df_nov['co2_ppm_deltaOne'] = df_nov['co2_ppm'] - df_nov.shift(1)['co2_ppm']\n",
    "df_nov['co2_ppm_deltaSix'] = df_nov['co2_ppm'] - df_nov.shift(6)['co2_ppm']\n",
    "df_nov['co2_ppm_deltaTwelve'] = df_nov['co2_ppm'] - df_nov.shift(12)['co2_ppm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e1263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wochentag einfuegen\n",
    "# verringert Genauigkeit, weil wahrscheinlich zu \"verlaesslich\"\n",
    "\n",
    "#df_test['dayOfWeek'] = df['timestamp'].dt.dayofweek\n",
    "#df_test = df_test.drop(df_test[df_test.dayOfWeek > 4].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausreisser mit Interquartile Range (IQR) und Tukey's Method loeschen\n",
    "# Idee: Fenster wird an fast allen Tagen ab ca. 1200-1300 ppm geoeffnet\n",
    "# -> was veraendert sich, wenn die Werte darüber entfernt werden und das Datenset so \"geglaettet\" wird?\n",
    "# Erhoeht Genauigkeit um ca. 2%\n",
    "outlier_indices = detectOutliers(df_test)\n",
    "df_test = df_test.drop(index=outlier_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcee49f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# timestamp, presence, temperatur und humidity entfernen\n",
    "# temp/humid erhoehen Genauigkeit deutlich, da relativ unverlaesslich -> von zu vielen aeusseren Faktoren abhaengig\n",
    "df_test = df_test.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "df_timestamp = df_test['timestamp']\n",
    "y_presence = df_test['presence']\n",
    "X_presence = df_test.drop(['timestamp', 'hoursMinutesSeconds', 'presence', 'temperature_celsius', 'relative_humidity_percent'], axis=1)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_presence, y_presence, test_size=0.2, random_state=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec61997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift des trainings-sets um 5 minuten in die Vergangenheit\n",
    "# -> Test ob Model auch in die Zukunft Erwartungen treffen kann\n",
    "#ytrain = ytrain.shift(-6)\n",
    "#ytrain.dropna(axis=0, how='any', inplace=False)\n",
    "#ytrain = ytrain.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301e2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classification\n",
    "modelClass = RandomForestClassifier()\n",
    "modelClass.fit(Xtrain, ytrain)\n",
    "#ypred = modelClass.predict(Xtest)\n",
    "rf_base_accuracy = evaluateClassifier(modelClass, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c473aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_class = Xtest.copy()\n",
    "df_valid_class['timestamp'] = df_timestamp\n",
    "df_valid_class['prediction'] = ypred\n",
    "df_valid_class['co2_ppm'] = df_test['co2_ppm']\n",
    "\n",
    "plt.scatter(df_valid_class, x='timestamp', y='co2_ppm', color='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638804d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot feature-importance\n",
    "feature_imp = pd.Series(modelClass.feature_importances_,index=Xtrain.columns).sort_values(ascending=False)\n",
    "# Creating a bar plot\n",
    "ax = sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "ax.set(xlabel='Importance', ylabel='Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7704563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Cross-Validation with Random Forest Classifier\n",
    "ytest_model = modelClass.fit(Xtrain, ytrain).predict(Xtest)\n",
    "ytrain_model = modelClass.fit(Xtest, ytest).predict(Xtrain)\n",
    "accuracy_score(ytrain, ytrain_model), accuracy_score(ytest, ytest_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1888f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Cross-Validation across n sets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(modelClass, X_presence, y_presence, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# falsche Werte im November korrigieren\n",
    "df_nov.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)\n",
    "df_timestamp_nov = df_nov['timestamp']\n",
    "df_nov.drop(['timestamp', 'hoursMinutesSeconds', 'presence', 'temperature_celsius', 'relative_humidity_percent'], axis=1, inplace=True)\n",
    "ypred_nov = modelClass.predict(df_nov)\n",
    "\n",
    "df_valid_nov = df_nov.copy()\n",
    "df_valid_nov['timestamp'] = df_timestamp_nov\n",
    "df_valid_nov['prediction'] = ypred_nov\n",
    "df_valid_nov['co2_ppm'] = df_nov['co2_ppm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64cbb1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_valid_nov, x='timestamp', y='co2_ppm', color='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a62a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameterTuning('RF', RandomForestClassifier(), Xtrain, ytrain, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663d9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameterTuning('GB', GradientBoostingClassifier(), Xtrain, ytrain, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca75654",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning('SVC', SVC(), Xtrain, ytrain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
